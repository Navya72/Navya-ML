Tutorial 3: Neural Network Classification
Dataset: Pima Indian Diabetes Dataset

This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.

Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.

Attributes of PIMA dataset:

Pregnancies: Number of times pregnant

Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test

BloodPressure: Diastolic blood pressure (mm Hg)

SkinThickness: Triceps skin fold thickness (mm)

Insulin: 2-Hour serum insulin (mu U/ml)

BMI: Body mass index (weight in kg/(height in m)^2)

DiabetesPedigreeFunction: Diabetes pedigree function

Age: Age (years)

Outcome: Class variable (0 or 1)

1. Mount the Google Drive

from google.colab import drive
drive.mount('/content/drive')
Mounted at /content/drive
2. Move to the place where data resides

%cd /content/drive/MyDrive/
/content/drive/MyDrive
!ls
3. Read the dataset from CSV file

import pandas as pd
data = pd.read_csv('diabetes.csv')
data.head(10)
Pregnancies	Glucose	BloodPressure	SkinThickness	Insulin	BMI	DiabetesPedigreeFunction	Age	Outcome
0	6	148	72	35	0	33.6	0.627	50	1
1	1	85	66	29	0	26.6	0.351	31	0
2	8	183	64	0	0	23.3	0.672	32	1
3	1	89	66	23	94	28.1	0.167	21	0
4	0	137	40	35	168	43.1	2.288	33	1
5	5	116	74	0	0	25.6	0.201	30	0
6	3	78	50	32	88	31.0	0.248	26	1
7	10	115	0	0	0	35.3	0.134	29	0
8	2	197	70	45	543	30.5	0.158	53	1
9	8	125	96	0	0	0.0	0.232	54	1
data.columns
Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',
       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],
      dtype='object')
data.values
array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],
       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],
       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],
       ...,
       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],
       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],
       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])
4. Store the data into input feature and label variables

dataset= data.values
X = dataset[:,0:8]
Y = dataset[:,8]
print(X)
print(Y)
[[  6.    148.     72.    ...  33.6     0.627  50.   ]
 [  1.     85.     66.    ...  26.6     0.351  31.   ]
 [  8.    183.     64.    ...  23.3     0.672  32.   ]
 ...
 [  5.    121.     72.    ...  26.2     0.245  30.   ]
 [  1.    126.     60.    ...  30.1     0.349  47.   ]
 [  1.     93.     70.    ...  30.4     0.315  23.   ]]
[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.
 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.
 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.
 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.
 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.
 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.
 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.
 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.
 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.
 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.
 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.
 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.
 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.
 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.
 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.
 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.
 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.
 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.
 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.
 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.
 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.
 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.
 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.
 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.
 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]

5. Data Normalization

from sklearn import preprocessing
min_max_scaler = preprocessing.MinMaxScaler()
X_scale = min_max_scaler.fit_transform(X)
X_scale
array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,
        0.48333333],
       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,
        0.16666667],
       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,
        0.18333333],
       ...,
       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,
        0.15      ],
       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,
        0.43333333],
       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,
        0.03333333]])
6. One-hot vector conversion

from keras.utils import np_utils
encoded_y = np_utils.to_categorical(Y)
encoded_y
array([[0., 1.],
       [1., 0.],
       [0., 1.],
       ...,
       [1., 0.],
       [0., 1.],
       [1., 0.]], dtype=float32)
7. Split the dataset into training, testing and validation set

from sklearn.model_selection import train_test_split
X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.5, random_state=10)
X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.5, random_state=10)
print(len(X_training))
print(len(X_testing))
print(len(X_valid))
192
384
192
8. Model Creation

from keras.models import Sequential
from keras.layers import Dense

# Creating the model
model = Sequential()
model.add(Dense(8, input_shape=(8,), activation='relu'))
model.add(Dense(12, activation='relu'))
model.add(Dense(2, activation='softmax'))
model.summary()   #gives a summary of the model
Model: "sequential_4"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_12 (Dense)            (None, 8)                 72        
                                                                 
 dense_13 (Dense)            (None, 12)                108       
                                                                 
 dense_14 (Dense)            (None, 2)                 26        
                                                                 
=================================================================
Total params: 206
Trainable params: 206
Non-trainable params: 0
_________________________________________________________________
9. Model Compile

from tensorflow.keras import optimizers
opt=optimizers.SGD(learning_rate=0.0001)
model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])
10. Model Training

if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.

hist = model.fit(X_training, Y_training,batch_size=4,  epochs=1000, validation_data=(X_valid,Y_valid))
Epoch 1/1000
48/48 [==============================] - 1s 7ms/step - loss: 0.8110 - accuracy: 0.3854 - val_loss: 0.8826 - val_accuracy: 0.3177
Epoch 2/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.8073 - accuracy: 0.3854 - val_loss: 0.8779 - val_accuracy: 0.3177
Epoch 3/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.8036 - accuracy: 0.3854 - val_loss: 0.8733 - val_accuracy: 0.3177
Epoch 4/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.8001 - accuracy: 0.3854 - val_loss: 0.8688 - val_accuracy: 0.3177
Epoch 5/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7966 - accuracy: 0.3854 - val_loss: 0.8644 - val_accuracy: 0.3177
Epoch 6/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7933 - accuracy: 0.3854 - val_loss: 0.8601 - val_accuracy: 0.3177
Epoch 7/1000
48/48 [==============================] - 0s 4ms/step - loss: 0.7900 - accuracy: 0.3854 - val_loss: 0.8559 - val_accuracy: 0.3177
Epoch 8/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7867 - accuracy: 0.3854 - val_loss: 0.8518 - val_accuracy: 0.3177
Epoch 9/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7836 - accuracy: 0.3854 - val_loss: 0.8478 - val_accuracy: 0.3177
Epoch 10/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7805 - accuracy: 0.3854 - val_loss: 0.8438 - val_accuracy: 0.3177
Epoch 11/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7775 - accuracy: 0.3854 - val_loss: 0.8399 - val_accuracy: 0.3177
Epoch 12/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7746 - accuracy: 0.3854 - val_loss: 0.8362 - val_accuracy: 0.3177
Epoch 13/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7717 - accuracy: 0.3854 - val_loss: 0.8324 - val_accuracy: 0.3177
Epoch 14/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7689 - accuracy: 0.3854 - val_loss: 0.8288 - val_accuracy: 0.3177
Epoch 15/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7662 - accuracy: 0.3854 - val_loss: 0.8253 - val_accuracy: 0.3177
Epoch 16/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7635 - accuracy: 0.3854 - val_loss: 0.8218 - val_accuracy: 0.3177
Epoch 17/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7609 - accuracy: 0.3854 - val_loss: 0.8184 - val_accuracy: 0.3177
Epoch 18/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7583 - accuracy: 0.3854 - val_loss: 0.8150 - val_accuracy: 0.3177
Epoch 19/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7558 - accuracy: 0.3854 - val_loss: 0.8118 - val_accuracy: 0.3177
Epoch 20/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7534 - accuracy: 0.3854 - val_loss: 0.8086 - val_accuracy: 0.3177
Epoch 21/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7510 - accuracy: 0.3854 - val_loss: 0.8054 - val_accuracy: 0.3177
Epoch 22/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7487 - accuracy: 0.3854 - val_loss: 0.8024 - val_accuracy: 0.3177
Epoch 23/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7464 - accuracy: 0.3854 - val_loss: 0.7993 - val_accuracy: 0.3177
Epoch 24/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.3854 - val_loss: 0.7964 - val_accuracy: 0.3177
Epoch 25/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7420 - accuracy: 0.3854 - val_loss: 0.7935 - val_accuracy: 0.3177
Epoch 26/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7399 - accuracy: 0.3854 - val_loss: 0.7907 - val_accuracy: 0.3177
Epoch 27/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.3854 - val_loss: 0.7879 - val_accuracy: 0.3177
Epoch 28/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7358 - accuracy: 0.3854 - val_loss: 0.7852 - val_accuracy: 0.3177
Epoch 29/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7338 - accuracy: 0.3854 - val_loss: 0.7825 - val_accuracy: 0.3177
Epoch 30/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7319 - accuracy: 0.3854 - val_loss: 0.7800 - val_accuracy: 0.3177
Epoch 31/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7300 - accuracy: 0.3854 - val_loss: 0.7774 - val_accuracy: 0.3177
Epoch 32/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.7282 - accuracy: 0.3854 - val_loss: 0.7749 - val_accuracy: 0.3177
Epoch 33/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7264 - accuracy: 0.3854 - val_loss: 0.7725 - val_accuracy: 0.3177
Epoch 34/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7247 - accuracy: 0.3854 - val_loss: 0.7701 - val_accuracy: 0.3177
Epoch 35/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7230 - accuracy: 0.3854 - val_loss: 0.7678 - val_accuracy: 0.3177
Epoch 36/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7213 - accuracy: 0.3854 - val_loss: 0.7655 - val_accuracy: 0.3177
Epoch 37/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7197 - accuracy: 0.3906 - val_loss: 0.7633 - val_accuracy: 0.3177
Epoch 38/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7181 - accuracy: 0.3958 - val_loss: 0.7611 - val_accuracy: 0.3177
Epoch 39/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7165 - accuracy: 0.3958 - val_loss: 0.7589 - val_accuracy: 0.3177
Epoch 40/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.7150 - accuracy: 0.3958 - val_loss: 0.7568 - val_accuracy: 0.3177
Epoch 41/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7136 - accuracy: 0.3958 - val_loss: 0.7548 - val_accuracy: 0.3177
Epoch 42/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.3958 - val_loss: 0.7528 - val_accuracy: 0.3177
Epoch 43/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7107 - accuracy: 0.3958 - val_loss: 0.7508 - val_accuracy: 0.3177
Epoch 44/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7093 - accuracy: 0.3958 - val_loss: 0.7488 - val_accuracy: 0.3177
Epoch 45/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7080 - accuracy: 0.3958 - val_loss: 0.7469 - val_accuracy: 0.3177
Epoch 46/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7066 - accuracy: 0.4010 - val_loss: 0.7450 - val_accuracy: 0.3229
Epoch 47/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7053 - accuracy: 0.4062 - val_loss: 0.7432 - val_accuracy: 0.3281
Epoch 48/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7041 - accuracy: 0.4062 - val_loss: 0.7414 - val_accuracy: 0.3281
Epoch 49/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7029 - accuracy: 0.4115 - val_loss: 0.7397 - val_accuracy: 0.3281
Epoch 50/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.4115 - val_loss: 0.7380 - val_accuracy: 0.3281
Epoch 51/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.7006 - accuracy: 0.4115 - val_loss: 0.7363 - val_accuracy: 0.3333
Epoch 52/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6994 - accuracy: 0.4167 - val_loss: 0.7347 - val_accuracy: 0.3385
Epoch 53/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6983 - accuracy: 0.4219 - val_loss: 0.7330 - val_accuracy: 0.3385
Epoch 54/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6972 - accuracy: 0.4219 - val_loss: 0.7314 - val_accuracy: 0.3385
Epoch 55/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6962 - accuracy: 0.4219 - val_loss: 0.7299 - val_accuracy: 0.3333
Epoch 56/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6951 - accuracy: 0.4219 - val_loss: 0.7284 - val_accuracy: 0.3333
Epoch 57/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.4323 - val_loss: 0.7269 - val_accuracy: 0.3438
Epoch 58/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.4375 - val_loss: 0.7255 - val_accuracy: 0.3438
Epoch 59/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.4479 - val_loss: 0.7240 - val_accuracy: 0.3438
Epoch 60/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.4531 - val_loss: 0.7227 - val_accuracy: 0.3438
Epoch 61/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.4531 - val_loss: 0.7213 - val_accuracy: 0.3490
Epoch 62/1000
48/48 [==============================] - 0s 4ms/step - loss: 0.6896 - accuracy: 0.4583 - val_loss: 0.7200 - val_accuracy: 0.3542
Epoch 63/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.4635 - val_loss: 0.7187 - val_accuracy: 0.3646
Epoch 64/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.4635 - val_loss: 0.7174 - val_accuracy: 0.3698
Epoch 65/1000
48/48 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.4688 - val_loss: 0.7161 - val_accuracy: 0.3698
Epoch 66/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.4740 - val_loss: 0.7149 - val_accuracy: 0.3698
Epoch 67/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.4792 - val_loss: 0.7137 - val_accuracy: 0.3698
Epoch 68/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.6848 - accuracy: 0.4896 - val_loss: 0.7125 - val_accuracy: 0.3698
Epoch 69/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6840 - accuracy: 0.4896 - val_loss: 0.7114 - val_accuracy: 0.3750
Epoch 70/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5000 - val_loss: 0.7103 - val_accuracy: 0.3802
Epoch 71/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.5052 - val_loss: 0.7092 - val_accuracy: 0.3854
Epoch 72/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.5156 - val_loss: 0.7081 - val_accuracy: 0.4010
Epoch 73/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.5312 - val_loss: 0.7070 - val_accuracy: 0.4167
Epoch 74/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.5469 - val_loss: 0.7060 - val_accuracy: 0.4271
Epoch 75/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6801 - accuracy: 0.5573 - val_loss: 0.7050 - val_accuracy: 0.4323
Epoch 76/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6795 - accuracy: 0.5625 - val_loss: 0.7041 - val_accuracy: 0.4323
Epoch 77/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6790 - accuracy: 0.5625 - val_loss: 0.7031 - val_accuracy: 0.4583
Epoch 78/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.5625 - val_loss: 0.7022 - val_accuracy: 0.4740
Epoch 79/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.5625 - val_loss: 0.7013 - val_accuracy: 0.4688
Epoch 80/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6773 - accuracy: 0.5677 - val_loss: 0.7004 - val_accuracy: 0.4740
Epoch 81/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.6767 - accuracy: 0.5781 - val_loss: 0.6995 - val_accuracy: 0.4792
Epoch 82/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6762 - accuracy: 0.5833 - val_loss: 0.6986 - val_accuracy: 0.4896
Epoch 83/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6756 - accuracy: 0.5833 - val_loss: 0.6977 - val_accuracy: 0.5000
Epoch 84/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.5833 - val_loss: 0.6969 - val_accuracy: 0.5000
Epoch 85/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.5833 - val_loss: 0.6961 - val_accuracy: 0.5104
Epoch 86/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.5885 - val_loss: 0.6952 - val_accuracy: 0.5156
Epoch 87/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6736 - accuracy: 0.5938 - val_loss: 0.6945 - val_accuracy: 0.5365
Epoch 88/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.6146 - val_loss: 0.6937 - val_accuracy: 0.5521
Epoch 89/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.6146 - val_loss: 0.6929 - val_accuracy: 0.5521
Epoch 90/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6722 - accuracy: 0.6198 - val_loss: 0.6921 - val_accuracy: 0.5677
Epoch 91/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6717 - accuracy: 0.6198 - val_loss: 0.6914 - val_accuracy: 0.5781
Epoch 92/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6302 - val_loss: 0.6907 - val_accuracy: 0.5833
Epoch 93/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6708 - accuracy: 0.6250 - val_loss: 0.6899 - val_accuracy: 0.5833
Epoch 94/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6704 - accuracy: 0.6250 - val_loss: 0.6892 - val_accuracy: 0.5938
Epoch 95/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.6354 - val_loss: 0.6885 - val_accuracy: 0.5938
Epoch 96/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.6354 - val_loss: 0.6878 - val_accuracy: 0.5990
Epoch 97/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6691 - accuracy: 0.6458 - val_loss: 0.6871 - val_accuracy: 0.6042
Epoch 98/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.6687 - accuracy: 0.6510 - val_loss: 0.6865 - val_accuracy: 0.6042
Epoch 99/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.6510 - val_loss: 0.6858 - val_accuracy: 0.6042
Epoch 100/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.6562 - val_loss: 0.6852 - val_accuracy: 0.6094
Epoch 101/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.6562 - val_loss: 0.6845 - val_accuracy: 0.6094
Epoch 102/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6672 - accuracy: 0.6667 - val_loss: 0.6839 - val_accuracy: 0.6198
Epoch 103/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6668 - accuracy: 0.6667 - val_loss: 0.6833 - val_accuracy: 0.6250
Epoch 104/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6664 - accuracy: 0.6667 - val_loss: 0.6827 - val_accuracy: 0.6302
Epoch 105/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6660 - accuracy: 0.6771 - val_loss: 0.6821 - val_accuracy: 0.6406
Epoch 106/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.6875 - val_loss: 0.6815 - val_accuracy: 0.6354
Epoch 107/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.6875 - val_loss: 0.6809 - val_accuracy: 0.6250
Epoch 108/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6650 - accuracy: 0.6823 - val_loss: 0.6803 - val_accuracy: 0.6302
Epoch 109/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.6875 - val_loss: 0.6798 - val_accuracy: 0.6406
Epoch 110/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.6875 - val_loss: 0.6792 - val_accuracy: 0.6406
Epoch 111/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.6639 - accuracy: 0.6927 - val_loss: 0.6786 - val_accuracy: 0.6510
Epoch 112/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6636 - accuracy: 0.6979 - val_loss: 0.6781 - val_accuracy: 0.6458
Epoch 113/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.7031 - val_loss: 0.6775 - val_accuracy: 0.6510
Epoch 114/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.7083 - val_loss: 0.6770 - val_accuracy: 0.6458
Epoch 115/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.7083 - val_loss: 0.6765 - val_accuracy: 0.6562
Epoch 116/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.7083 - val_loss: 0.6760 - val_accuracy: 0.6615
Epoch 117/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6620 - accuracy: 0.7083 - val_loss: 0.6754 - val_accuracy: 0.6615
Epoch 118/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.7083 - val_loss: 0.6749 - val_accuracy: 0.6562
Epoch 119/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.7083 - val_loss: 0.6744 - val_accuracy: 0.6615
Epoch 120/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.7083 - val_loss: 0.6739 - val_accuracy: 0.6615
Epoch 121/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6608 - accuracy: 0.7135 - val_loss: 0.6734 - val_accuracy: 0.6615
Epoch 122/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.7188 - val_loss: 0.6729 - val_accuracy: 0.6667
Epoch 123/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 0.7240 - val_loss: 0.6725 - val_accuracy: 0.6719
Epoch 124/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.7292 - val_loss: 0.6720 - val_accuracy: 0.6615
Epoch 125/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.7344 - val_loss: 0.6715 - val_accuracy: 0.6615
Epoch 126/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.7292 - val_loss: 0.6711 - val_accuracy: 0.6667
Epoch 127/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.7292 - val_loss: 0.6706 - val_accuracy: 0.6823
Epoch 128/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.7135 - val_loss: 0.6702 - val_accuracy: 0.6823
Epoch 129/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.6584 - accuracy: 0.7135 - val_loss: 0.6697 - val_accuracy: 0.6771
Epoch 130/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.7135 - val_loss: 0.6693 - val_accuracy: 0.6771
Epoch 131/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.7240 - val_loss: 0.6688 - val_accuracy: 0.6823
Epoch 132/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6576 - accuracy: 0.7188 - val_loss: 0.6684 - val_accuracy: 0.6875
Epoch 133/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.7188 - val_loss: 0.6680 - val_accuracy: 0.6927
Epoch 134/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.7188 - val_loss: 0.6676 - val_accuracy: 0.6927
Epoch 135/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6568 - accuracy: 0.7240 - val_loss: 0.6672 - val_accuracy: 0.6979
Epoch 136/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6566 - accuracy: 0.7188 - val_loss: 0.6668 - val_accuracy: 0.6979
Epoch 137/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.7188 - val_loss: 0.6664 - val_accuracy: 0.7031
Epoch 138/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.7135 - val_loss: 0.6659 - val_accuracy: 0.6823
Epoch 139/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6558 - accuracy: 0.7240 - val_loss: 0.6655 - val_accuracy: 0.6823
Epoch 140/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6556 - accuracy: 0.7240 - val_loss: 0.6652 - val_accuracy: 0.6823
Epoch 141/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.7240 - val_loss: 0.6648 - val_accuracy: 0.6927
Epoch 142/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6551 - accuracy: 0.7240 - val_loss: 0.6644 - val_accuracy: 0.6927
Epoch 143/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.7240 - val_loss: 0.6640 - val_accuracy: 0.6979
Epoch 144/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6546 - accuracy: 0.7240 - val_loss: 0.6636 - val_accuracy: 0.6979
Epoch 145/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.7188 - val_loss: 0.6632 - val_accuracy: 0.7031
Epoch 146/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6542 - accuracy: 0.7188 - val_loss: 0.6629 - val_accuracy: 0.7083
Epoch 147/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.7135 - val_loss: 0.6625 - val_accuracy: 0.6979
Epoch 148/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.7188 - val_loss: 0.6621 - val_accuracy: 0.6979
Epoch 149/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.7135 - val_loss: 0.6617 - val_accuracy: 0.6979
Epoch 150/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.7083 - val_loss: 0.6614 - val_accuracy: 0.6979
Epoch 151/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6531 - accuracy: 0.7135 - val_loss: 0.6610 - val_accuracy: 0.6875
Epoch 152/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.7135 - val_loss: 0.6607 - val_accuracy: 0.6875
Epoch 153/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6526 - accuracy: 0.7083 - val_loss: 0.6603 - val_accuracy: 0.6875
Epoch 154/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.7083 - val_loss: 0.6600 - val_accuracy: 0.6771
Epoch 155/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.7083 - val_loss: 0.6596 - val_accuracy: 0.6771
Epoch 156/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6520 - accuracy: 0.7083 - val_loss: 0.6593 - val_accuracy: 0.6771
Epoch 157/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.7083 - val_loss: 0.6589 - val_accuracy: 0.6771
Epoch 158/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6516 - accuracy: 0.7083 - val_loss: 0.6586 - val_accuracy: 0.6667
Epoch 159/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.6514 - accuracy: 0.7083 - val_loss: 0.6583 - val_accuracy: 0.6719
Epoch 160/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6511 - accuracy: 0.7083 - val_loss: 0.6579 - val_accuracy: 0.6771
Epoch 161/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6509 - accuracy: 0.7083 - val_loss: 0.6576 - val_accuracy: 0.6667
Epoch 162/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.7031 - val_loss: 0.6573 - val_accuracy: 0.6667
Epoch 163/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.7083 - val_loss: 0.6569 - val_accuracy: 0.6719
Epoch 164/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.7031 - val_loss: 0.6566 - val_accuracy: 0.6719
Epoch 165/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.7083 - val_loss: 0.6563 - val_accuracy: 0.6823
Epoch 166/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.7083 - val_loss: 0.6559 - val_accuracy: 0.6823
Epoch 167/1000
48/48 [==============================] - 0s 4ms/step - loss: 0.6497 - accuracy: 0.7083 - val_loss: 0.6556 - val_accuracy: 0.6823
Epoch 168/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6495 - accuracy: 0.7135 - val_loss: 0.6553 - val_accuracy: 0.6823
Epoch 169/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.7135 - val_loss: 0.6550 - val_accuracy: 0.6771
Epoch 170/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.7135 - val_loss: 0.6547 - val_accuracy: 0.6875
Epoch 171/1000
48/48 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.7083 - val_loss: 0.6544 - val_accuracy: 0.6875
Epoch 172/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6487 - accuracy: 0.7083 - val_loss: 0.6541 - val_accuracy: 0.6927
Epoch 173/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6485 - accuracy: 0.7083 - val_loss: 0.6538 - val_accuracy: 0.6979
Epoch 174/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.7083 - val_loss: 0.6534 - val_accuracy: 0.6979
Epoch 175/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.7031 - val_loss: 0.6531 - val_accuracy: 0.6979
Epoch 176/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.7031 - val_loss: 0.6529 - val_accuracy: 0.7031
Epoch 177/1000
48/48 [==============================] - 0s 4ms/step - loss: 0.6478 - accuracy: 0.7031 - val_loss: 0.6526 - val_accuracy: 0.7083
Epoch 178/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.6979 - val_loss: 0.6523 - val_accuracy: 0.7083
Epoch 179/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.6979 - val_loss: 0.6520 - val_accuracy: 0.7031
Epoch 180/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.6979 - val_loss: 0.6517 - val_accuracy: 0.7031
Epoch 181/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.6979 - val_loss: 0.6514 - val_accuracy: 0.7083
Epoch 182/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6468 - accuracy: 0.6979 - val_loss: 0.6511 - val_accuracy: 0.7083
Epoch 183/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.6979 - val_loss: 0.6509 - val_accuracy: 0.7083
Epoch 184/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.6979 - val_loss: 0.6506 - val_accuracy: 0.7083
Epoch 185/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6463 - accuracy: 0.6979 - val_loss: 0.6503 - val_accuracy: 0.7083
Epoch 186/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6927 - val_loss: 0.6500 - val_accuracy: 0.7083
Epoch 187/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6460 - accuracy: 0.6927 - val_loss: 0.6498 - val_accuracy: 0.7083
Epoch 188/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.6979 - val_loss: 0.6495 - val_accuracy: 0.7083
Epoch 189/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6979 - val_loss: 0.6492 - val_accuracy: 0.7083
Epoch 190/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6455 - accuracy: 0.6979 - val_loss: 0.6490 - val_accuracy: 0.7031
Epoch 191/1000
48/48 [==============================] - 0s 5ms/step - loss: 0.6453 - accuracy: 0.6979 - val_loss: 0.6487 - val_accuracy: 0.7031
Epoch 192/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6979 - val_loss: 0.6485 - val_accuracy: 0.6979
Epoch 193/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6450 - accuracy: 0.6979 - val_loss: 0.6482 - val_accuracy: 0.6979
Epoch 194/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6448 - accuracy: 0.6979 - val_loss: 0.6480 - val_accuracy: 0.6927
Epoch 195/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6447 - accuracy: 0.6979 - val_loss: 0.6477 - val_accuracy: 0.6927
Epoch 196/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.6927 - val_loss: 0.6475 - val_accuracy: 0.6927
Epoch 197/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.6979 - val_loss: 0.6472 - val_accuracy: 0.6927
Epoch 198/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6927 - val_loss: 0.6470 - val_accuracy: 0.6927
Epoch 199/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6927 - val_loss: 0.6468 - val_accuracy: 0.6927
Epoch 200/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6439 - accuracy: 0.6927 - val_loss: 0.6465 - val_accuracy: 0.6875
Epoch 201/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.6927 - val_loss: 0.6463 - val_accuracy: 0.6875
Epoch 202/1000
48/48 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6875 - val_loss: 0.6461 - val_accuracy: 0.6875
Epoch 203/1000
11. Plot the training loss and accuracy

import matplotlib.pyplot as plt 
acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']
loss = hist.history['loss']
val_loss = hist.history['val_loss']
 
epochs = range(len(acc))
 
plt.plot(epochs, acc, 'b', label='Training acc')
plt.plot(epochs, val_acc, 'r', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()
plt.savefig('custom_trainvalacc.png')
plt.figure()
 
plt.plot(epochs, loss, 'b', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
 
#plt.show()
plt.savefig('custom_trainvalloss.png')
plt.figure()
<Figure size 432x288 with 0 Axes>


<Figure size 432x288 with 0 Axes>
12. Evaluate the performance

res =model.evaluate(X_testing, Y_testing)
12/12 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.6797
13. Predict on new datatset

test=X_testing[0]
y_act=Y_testing[0]
result=model.predict(test.reshape(1,8))
result
array([[0.5429038 , 0.45709625]], dtype=float32)
import numpy as np
y_pred = np.round(result)
print("Actual:"+ str(y_act))
print("Predicted:"+str(y_pred))
Actual:[1. 0.]
Predicted:[[1. 0.]]

